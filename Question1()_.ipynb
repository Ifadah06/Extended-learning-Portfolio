{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKI5IoivPQA6hPk8Gd7QRb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ifadah06/Extended-learning-Portfolio/blob/main/Question1()_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1\n",
        "\n",
        "Write a Python program within this or another notebook that performs advanced file analysis. The program should prompt the user to enter the path to a text file and allow them to choose from various analysis options:\n",
        "Counting the number of lines.\n",
        "Counting the total number of words.\n",
        "Counting the total number of characters, both including and excluding whitespace.\n",
        "Identifying the frequency of each word in the text.\n",
        "Identifying the top 5 most common words in the text.\n",
        "After receiving the user input, your program should read the file and perform the chosen analysis, outputting the results in a clear, human-readable format.\n",
        "Question subparts:\n",
        "Implement the notebook program as described above. Your program should be robust and handle possible edge cases, such as file not found or incorrect input from the user.\n",
        "Write a brief description of your program, explaining how to use it and what each analysis option does. This description should be written as if for other developers or users who might use your tool.\n",
        "Write a few test cases to validate your tool. Consider edge cases such as empty files, very large files, files with unusual characters, and so on.\n",
        "Discuss how you would modify your tool to analyze binary files, or large files that do not fit into memory. What kind of analysis could be useful in these cases?\n",
        "Provide a few example text files and show the output of your program when run with these files.\n",
        "Remember to include necessary error handling in your program to make it robust and reliable."
      ],
      "metadata": {
        "id": "P2s7EGRkLeHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import collections\n",
        "\n",
        "def count_lines(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    return len(lines)\n",
        "\n",
        "def count_words(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "    words = content.split()\n",
        "    return len(words)\n",
        "\n",
        "def count_characters(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "    return len(content)\n",
        "\n",
        "def count_word_frequency(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "    words = content.split()\n",
        "    word_count = collections.Counter(words)\n",
        "    return word_count\n",
        "\n",
        "def get_most_common_words(file_path, count=5):\n",
        "    word_count = count_word_frequency(file_path)\n",
        "    return word_count.most_common(count)\n",
        "\n",
        "def prompt_for_file():\n",
        "    while True:\n",
        "        file_path = input(\"Enter the path to a text file: \")\n",
        "        if os.path.isfile(file_path):\n",
        "            return file_path\n",
        "        else:\n",
        "            print(\"File not found. Please enter a valid file path.\")\n",
        "\n",
        "def display_results(results):\n",
        "    print(\"\\nResults:\")\n",
        "    for key, value in results.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "def analyze_file():\n",
        "    print(\"Welcome to the File Analyzer!\")\n",
        "    file_path = prompt_for_file()\n",
        "\n",
        "    print(\"\\nAnalysis Options:\")\n",
        "    print(\"1. Count lines\")\n",
        "    print(\"2. Count words\")\n",
        "    print(\"3. Count characters\")\n",
        "    print(\"4. Count word frequency\")\n",
        "    print(\"5. Get most common words\")\n",
        "\n",
        "    choice = input(\"Enter the number of the analysis option you want: \")\n",
        "\n",
        "    if choice == '1':\n",
        "        lines = count_lines(file_path)\n",
        "        display_results({\"Lines\": lines})\n",
        "    elif choice == '2':\n",
        "        words = count_words(file_path)\n",
        "        display_results({\"Words\": words})\n",
        "    elif choice == '3':\n",
        "        characters = count_characters(file_path)\n",
        "        display_results({\"Characters\": characters})\n",
        "    elif choice == '4':\n",
        "        word_count = count_word_frequency(file_path)\n",
        "        display_results(word_count)\n",
        "    elif choice == '5':\n",
        "        count = int(input(\"Enter the number of most common words you want: \"))\n",
        "        most_common_words = get_most_common_words(file_path, count)\n",
        "        display_results(dict(most_common_words))\n",
        "    else:\n",
        "        print(\"Invalid choice. Please select a number from the menu.\")\n",
        "\n",
        "# Run the file analyzer\n",
        "analyze_file()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVrJGLuwLgAf",
        "outputId": "81bfbf86-8041-4fb4-f8e7-003505c40c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the File Analyzer!\n",
            "Enter the path to a text file: /content/sample_data/california_housing_test.csv\n",
            "\n",
            "Analysis Options:\n",
            "1. Count lines\n",
            "2. Count words\n",
            "3. Count characters\n",
            "4. Count word frequency\n",
            "5. Get most common words\n",
            "Enter the number of the analysis option you want: 5\n",
            "Enter the number of most common words you want: 5\n",
            "\n",
            "Results:\n",
            "\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\": 1\n",
            "-122.050000,37.370000,27.000000,3885.000000,661.000000,1537.000000,606.000000,6.608500,344700.000000: 1\n",
            "-118.300000,34.260000,43.000000,1510.000000,310.000000,809.000000,277.000000,3.599000,176500.000000: 1\n",
            "-117.810000,33.780000,27.000000,3589.000000,507.000000,1484.000000,495.000000,5.793400,270500.000000: 1\n",
            "-118.360000,33.820000,28.000000,67.000000,15.000000,49.000000,11.000000,6.135900,330000.000000: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "i had several issues whe running thw program.Firstly,i was confused about importing the modules.Secondly, when i was inserting some files in the file Analyser it resulted to errors constantly.Then i used chatgpt for help to solve those issues,where i found that i shoulve have extracted the\n",
        "files from file browsing on googlke colab itself\n",
        "ref:\n",
        "According to  Screen Shot 2023-06-12 at 15.05"
      ],
      "metadata": {
        "id": "JsTUm7qohMsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above scenario/code the current script has a command-line interface that lets the user enter the file path of a text file and choose from a number of analysis choices. The functions count_lines, count_words, count_characters, count_word_frequency, and get_most_common_words take care of the different analysis jobs. The goal of the function prompt_for_file is to make sure that the user's file path is correct, whereas the function display_results is to show the results of the analysis."
      ],
      "metadata": {
        "id": "wtMCm5aiQuTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some examples of text files can be as shown below:"
      ],
      "metadata": {
        "id": "bwqmiyFcQ8CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#empty.txt (an empty file)"
      ],
      "metadata": {
        "id": "GnRFiy2PRQR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example.txt:\n",
        "Hello, world!"
      ],
      "metadata": {
        "id": "W8XmUEBFTB8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#special_chars.txt:\n",
        "\n",
        "!@   #$%^&*()-_=+[]{};:'\",.<>/?\\|\n",
        "``\n"
      ],
      "metadata": {
        "id": "wsFeFYARRVmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discuss how you would modify your tool to analyze binary files, or large files that do not fit into memory. What kind of analysis could be useful in these cases?\n",
        "\n",
        "\n",
        "1.Stream-processing:It is a process where a tool is changed by processing data in small pieces, or streams, instead of putting the whole file into memory.This method can be very helpful when working with large data files.\n",
        "\n",
        "2.Handling Binary File: Since binary files don't have text data, they are handled differently than text files. This means that the research methods used for text files can't be used for binary files. So that the tool can handle binary files, it may give more weight to looking at the binary data itself.\n",
        "\n",
        "3.Disk-based data: When working with large files,the tool can make the best use of its memory by using data structures or databases that make it easy to store data on disk. This makes it easy to view and process the data. \n",
        "\n",
        "4.Partial Analysis: When the size of the file prevents full processing, the tool can be used to do a partial study. The program can look at a certain part of the file or different parts of the file one at a time, giving conclusions that depend on the parts that were looked at.\n",
        "\n",
        "ref:\n",
        "According to Screen Shot 2023-06-12 at 15.07"
      ],
      "metadata": {
        "id": "7FQ8NHZzTEQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some examples of binary files and and large files'text files can be shown below:"
      ],
      "metadata": {
        "id": "MkJvK9ZEWK1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example File 1 - \"sample1.txt\":\n",
        "\n"
      ],
      "metadata": {
        "id": "MtCLBX7iWe8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This is a sample text file.\n",
        "#It includes multiple lines of text.\n",
        "#This file is used for testing the file analyzer program."
      ],
      "metadata": {
        "id": "zwrJ8op9WlvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Count Lines:\n",
        "\n"
      ],
      "metadata": {
        "id": "-MdA_lsWWfBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BNF3WOwihzm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Results:\n",
        "Lines: 3"
      ],
      "metadata": {
        "id": "OLOUpW0wWrmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Word Frequency:"
      ],
      "metadata": {
        "id": "q-n-zsb2WfHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Results:\n",
        "This: 1\n",
        "is: 1\n",
        "a: 1\n",
        "sample: 1\n",
        "text: 2\n",
        "file.: 1\n",
        "It: 1\n",
        "contains: 1\n",
        "multiple: 1\n",
        "lines: 1\n",
        "of: 1\n",
        "The: 1\n",
        "file: 1\n",
        "used: 1\n",
        "for: 1\n",
        "testing: 1\n",
        "the: 1\n",
        "analyzer: 1\n",
        "program.: 1"
      ],
      "metadata": {
        "id": "mC4_3irmWz0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Count Words:"
      ],
      "metadata": {
        "id": "W5M-5_85XHGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Results:\n",
        "Words: 15"
      ],
      "metadata": {
        "id": "LSxGEivSXJET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ref:\n",
        "According to Screen Shot 2023-06-12 at 15.31."
      ],
      "metadata": {
        "id": "40gReH-Ih0iO"
      }
    }
  ]
}